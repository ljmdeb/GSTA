{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing a Black-box model by a Global Single Tree Approximation\n",
    "#A classification case, with both random and deterministic data generation\n",
    "#Laurent Deborde 2019 march 23th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30)\n"
     ]
    }
   ],
   "source": [
    "#load dataset\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "cancer = load_breast_cancer()\n",
    "print(cancer.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>0.062798</td>\n",
       "      <td>...</td>\n",
       "      <td>16.269190</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>...</td>\n",
       "      <td>4.833242</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.049960</td>\n",
       "      <td>...</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>...</td>\n",
       "      <td>13.010000</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>...</td>\n",
       "      <td>14.970000</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>0.066120</td>\n",
       "      <td>...</td>\n",
       "      <td>18.790000</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.097440</td>\n",
       "      <td>...</td>\n",
       "      <td>36.040000</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2            3           4   \\\n",
       "count  569.000000  569.000000  569.000000   569.000000  569.000000   \n",
       "mean    14.127292   19.289649   91.969033   654.889104    0.096360   \n",
       "std      3.524049    4.301036   24.298981   351.914129    0.014064   \n",
       "min      6.981000    9.710000   43.790000   143.500000    0.052630   \n",
       "25%     11.700000   16.170000   75.170000   420.300000    0.086370   \n",
       "50%     13.370000   18.840000   86.240000   551.100000    0.095870   \n",
       "75%     15.780000   21.800000  104.100000   782.700000    0.105300   \n",
       "max     28.110000   39.280000  188.500000  2501.000000    0.163400   \n",
       "\n",
       "               5           6           7           8           9      ...      \\\n",
       "count  569.000000  569.000000  569.000000  569.000000  569.000000     ...       \n",
       "mean     0.104341    0.088799    0.048919    0.181162    0.062798     ...       \n",
       "std      0.052813    0.079720    0.038803    0.027414    0.007060     ...       \n",
       "min      0.019380    0.000000    0.000000    0.106000    0.049960     ...       \n",
       "25%      0.064920    0.029560    0.020310    0.161900    0.057700     ...       \n",
       "50%      0.092630    0.061540    0.033500    0.179200    0.061540     ...       \n",
       "75%      0.130400    0.130700    0.074000    0.195700    0.066120     ...       \n",
       "max      0.345400    0.426800    0.201200    0.304000    0.097440     ...       \n",
       "\n",
       "               20          21          22           23          24  \\\n",
       "count  569.000000  569.000000  569.000000   569.000000  569.000000   \n",
       "mean    16.269190   25.677223  107.261213   880.583128    0.132369   \n",
       "std      4.833242    6.146258   33.602542   569.356993    0.022832   \n",
       "min      7.930000   12.020000   50.410000   185.200000    0.071170   \n",
       "25%     13.010000   21.080000   84.110000   515.300000    0.116600   \n",
       "50%     14.970000   25.410000   97.660000   686.500000    0.131300   \n",
       "75%     18.790000   29.720000  125.400000  1084.000000    0.146000   \n",
       "max     36.040000   49.540000  251.200000  4254.000000    0.222600   \n",
       "\n",
       "               25          26          27          28          29  \n",
       "count  569.000000  569.000000  569.000000  569.000000  569.000000  \n",
       "mean     0.254265    0.272188    0.114606    0.290076    0.083946  \n",
       "std      0.157336    0.208624    0.065732    0.061867    0.018061  \n",
       "min      0.027290    0.000000    0.000000    0.156500    0.055040  \n",
       "25%      0.147200    0.114500    0.064930    0.250400    0.071460  \n",
       "50%      0.211900    0.226700    0.099930    0.282200    0.080040  \n",
       "75%      0.339100    0.382900    0.161400    0.317900    0.092080  \n",
       "max      1.058000    1.252000    0.291000    0.663800    0.207500  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#build dataframe\n",
    "import pandas as pd\n",
    "X = pd.DataFrame(cancer['data'])\n",
    "y = cancer ['target']\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate between train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target,stratify=cancer.target, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First let's try to fit a single tree to the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'max_depth': range(1,10)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': 2}\n",
      "Best cross-validation score: 0.933\n",
      "Test set score: 0.938\n"
     ]
    }
   ],
   "source": [
    "grid_search = GridSearchCV(DecisionTreeClassifier(), param_grid, scoring= 'roc_auc', cv=5,return_train_score=True)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"Best cross-validation score: {:.3f}\".format(grid_search.best_score_))\n",
    "print(\"Test set score: {:.3f}\".format(grid_search.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The optimal max_depth seems to be 2 (quite low). Let's fit a tree of such depth on the whole training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for depth 2\n",
      "accuracy on training set is 0.946\n",
      "accuracy on test set is 0.923\n",
      "roc_auc_score on test set is 0.919\n"
     ]
    }
   ],
   "source": [
    "k=2\n",
    "tree = DecisionTreeClassifier(max_depth=k)\n",
    "tree.fit(X_train,y_train)\n",
    "Acc_appr=tree.score(X_train,y_train)\n",
    "Acc_test=tree.score(X_test,y_test)\n",
    "y_pred=tree.predict(X_test)\n",
    "roc_test=roc_auc_score(y_test, y_pred)\n",
    "print('for depth',k)\n",
    "print(\"accuracy on training set is {:.3f}\".format(Acc_appr))\n",
    "print(\"accuracy on test set is {:.3f}\".format(Acc_test))\n",
    "print(\"roc_auc_score on test set is {:.3f}\".format(roc_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try a Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': 4, 'max_features': 5}\n",
      "Best cross-validation score: 0.990\n",
      "Test set score: 0.991\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'max_depth': [1,2,3,4,5,6,None], 'max_features': [3,5,7,10, None]}\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "grid_search = GridSearchCV(RandomForestClassifier(), param_grid, scoring= 'roc_auc', cv=5,return_train_score=True)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"Best cross-validation score: {:.3f}\".format(grid_search.best_score_))\n",
    "print(\"Test set score: {:.3f}\".format(grid_search.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results are much better than with the single tree. Let's fit the RF on the whole training set with the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on training set is 0.993\n",
      "accuracy on test set is 0.944\n",
      "roc_auc_score on test set is 0.940\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(max_depth= 6, max_features= 5)\n",
    "np.set_printoptions(precision=3)\n",
    "rfc.fit(X_train,y_train)\n",
    "y_pred=rfc.predict(X_test)\n",
    "roc_test=roc_auc_score(y_test, y_pred)\n",
    "print(\"accuracy on training set is {:.3f}\".format(rfc.score(X_train,y_train)))\n",
    "print(\"accuracy on test set is {:.3f}\".format(rfc.score(X_test,y_test)))\n",
    "print(\"roc_auc_score on test set is {:.3f}\".format(roc_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Significantly above the single tree results.\n",
    "### Let's try also a Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'learning_rate': 0.03, 'max_depth': 5, 'max_features': 2}\n",
      "Best cross-validation score: 0.992\n",
      "Test set score: 0.993\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "param_grid = {'max_depth': [1,3,5,None],'max_features': [1,2,3,5,10,None],'learning_rate' : [0.03,0.1,0.5]}\n",
    "grid_search = GridSearchCV(GradientBoostingClassifier(), param_grid,scoring= 'roc_auc', cv=5, return_train_score=True)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"Best cross-validation score: {:.3f}\".format(grid_search.best_score_))\n",
    "print(\"Test set score: {:.3f}\".format(grid_search.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on the training set is 1.000\n",
      "accuracy on the test set is 0.958\n",
      "roc_auc_score on test set is 0.951\n"
     ]
    }
   ],
   "source": [
    "# let's fit the best parameters on the whole training set\n",
    "gbr = GradientBoostingClassifier(max_depth=5, max_features=2,learning_rate=0.03)\n",
    "np.set_printoptions(precision=3)\n",
    "gbr.fit(X_train,y_train)\n",
    "y_pred=gbr.predict(X_test)\n",
    "roc_test=roc_auc_score(y_test, y_pred)\n",
    "print(\"accuracy on the training set is {:.3f}\".format(gbr.score(X_train,y_train)))\n",
    "print(\"accuracy on the test set is {:.3f}\".format(gbr.score(X_test,y_test)))\n",
    "print(\"roc_auc_score on test set is {:.3f}\".format(roc_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#as an andditionnal measure of prudence, let's try a GB with default parameters : a good result will alleviate fear of overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on the training set is 1.000\n",
      "accuracy on the test set is 0.958\n",
      "roc_auc_score on test set is 0.947\n"
     ]
    }
   ],
   "source": [
    "gbr = GradientBoostingClassifier()\n",
    "np.set_printoptions(precision=3)\n",
    "gbr.fit(X_train,y_train)\n",
    "y_pred=gbr.predict(X_test)\n",
    "roc_test=roc_auc_score(y_test, y_pred)\n",
    "print(\"accuracy on the training set is {:.3f}\".format(gbr.score(X_train,y_train)))\n",
    "print(\"accuracy on the test set is {:.3f}\".format(gbr.score(X_test,y_test)))\n",
    "print(\"roc_auc_score on test set is {:.3f}\".format(roc_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Both RF and GB are significantly better than Single Tree. \n",
    "\n",
    "## Q : Let's suppose that for some reasons (need for transparency) we are not allowed to use RF, GB, or other good but complex models. Can we use knowledge from the RF and/or GB to build a better single tree ? \n",
    "## A :Yes indeed. It's usually done for the purpose of explanation of complex models. \n",
    "\n",
    "\n",
    "## We know that a single tree would have better accuracy if trained on a larger number of data. Let's supplement the original dataset by a synthetic one, for which labels will be predicted by the RF or GB, used as a  kind of oracle.  We'll then try to fit a single tree on this larger data set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, let's generate new \"synthetic\" data points. \n",
    "### We want them to be numerous, and statistically similar to the original points in the dataset (because we suppose our original data set to be similar to the actual data the model will be used on).\n",
    "### To do so, we will create them according to a multivariate gaussian distribution with parameters estimated on the original data (A more rigorous approach would be to observe the form of the statistic distribution of the data set and infer from it the distribution shape rather than postulating it's gaussian. An even better strategy if possible would be to use real life unlabelled data). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First let's estimate the parameters of the gaussian distribution on the training set (some feel authorized to also use the test set in such procedure as labels are not used here. I prefer to abstain from it as in real life variables values for data to be labeled are generaly not known when building the model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= pd.DataFrame(X_train)\n",
    "echmean=X_train.mean(axis=0)\n",
    "echcov= X_train.cov()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's draw at random a LARGE number of points according to this distribution. Too large a number will impair computation time, to low a number will impair accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.098702</td>\n",
       "      <td>19.295169</td>\n",
       "      <td>91.756108</td>\n",
       "      <td>651.800128</td>\n",
       "      <td>0.096034</td>\n",
       "      <td>0.103642</td>\n",
       "      <td>0.089314</td>\n",
       "      <td>0.048422</td>\n",
       "      <td>0.180263</td>\n",
       "      <td>0.062772</td>\n",
       "      <td>...</td>\n",
       "      <td>16.226747</td>\n",
       "      <td>25.709159</td>\n",
       "      <td>106.992103</td>\n",
       "      <td>875.027629</td>\n",
       "      <td>0.132329</td>\n",
       "      <td>0.256093</td>\n",
       "      <td>0.278126</td>\n",
       "      <td>0.114411</td>\n",
       "      <td>0.291184</td>\n",
       "      <td>0.084052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.519180</td>\n",
       "      <td>4.446081</td>\n",
       "      <td>24.249636</td>\n",
       "      <td>347.062905</td>\n",
       "      <td>0.013356</td>\n",
       "      <td>0.052704</td>\n",
       "      <td>0.081072</td>\n",
       "      <td>0.038583</td>\n",
       "      <td>0.027709</td>\n",
       "      <td>0.007269</td>\n",
       "      <td>...</td>\n",
       "      <td>4.818615</td>\n",
       "      <td>6.306801</td>\n",
       "      <td>33.518099</td>\n",
       "      <td>560.404074</td>\n",
       "      <td>0.022713</td>\n",
       "      <td>0.162484</td>\n",
       "      <td>0.219551</td>\n",
       "      <td>0.067366</td>\n",
       "      <td>0.065595</td>\n",
       "      <td>0.018830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.281599</td>\n",
       "      <td>-0.140407</td>\n",
       "      <td>-8.731018</td>\n",
       "      <td>-741.775730</td>\n",
       "      <td>0.034892</td>\n",
       "      <td>-0.123739</td>\n",
       "      <td>-0.252489</td>\n",
       "      <td>-0.116072</td>\n",
       "      <td>0.063134</td>\n",
       "      <td>0.028762</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.958019</td>\n",
       "      <td>0.179834</td>\n",
       "      <td>-42.715090</td>\n",
       "      <td>-1632.642562</td>\n",
       "      <td>0.036083</td>\n",
       "      <td>-0.465006</td>\n",
       "      <td>-0.585651</td>\n",
       "      <td>-0.159343</td>\n",
       "      <td>0.014209</td>\n",
       "      <td>-0.005314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.716777</td>\n",
       "      <td>16.307522</td>\n",
       "      <td>75.354290</td>\n",
       "      <td>417.743091</td>\n",
       "      <td>0.087065</td>\n",
       "      <td>0.068066</td>\n",
       "      <td>0.034279</td>\n",
       "      <td>0.022478</td>\n",
       "      <td>0.161636</td>\n",
       "      <td>0.057900</td>\n",
       "      <td>...</td>\n",
       "      <td>12.987974</td>\n",
       "      <td>21.466966</td>\n",
       "      <td>84.442552</td>\n",
       "      <td>498.235106</td>\n",
       "      <td>0.117078</td>\n",
       "      <td>0.146563</td>\n",
       "      <td>0.129664</td>\n",
       "      <td>0.068884</td>\n",
       "      <td>0.246983</td>\n",
       "      <td>0.071350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>14.096291</td>\n",
       "      <td>19.296790</td>\n",
       "      <td>91.731903</td>\n",
       "      <td>650.839715</td>\n",
       "      <td>0.096036</td>\n",
       "      <td>0.103706</td>\n",
       "      <td>0.089293</td>\n",
       "      <td>0.048362</td>\n",
       "      <td>0.180319</td>\n",
       "      <td>0.062779</td>\n",
       "      <td>...</td>\n",
       "      <td>16.219209</td>\n",
       "      <td>25.704349</td>\n",
       "      <td>106.938066</td>\n",
       "      <td>874.847927</td>\n",
       "      <td>0.132365</td>\n",
       "      <td>0.255991</td>\n",
       "      <td>0.277674</td>\n",
       "      <td>0.114428</td>\n",
       "      <td>0.291551</td>\n",
       "      <td>0.084057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>16.470124</td>\n",
       "      <td>22.299332</td>\n",
       "      <td>108.119079</td>\n",
       "      <td>886.710120</td>\n",
       "      <td>0.105055</td>\n",
       "      <td>0.139306</td>\n",
       "      <td>0.144352</td>\n",
       "      <td>0.074431</td>\n",
       "      <td>0.198926</td>\n",
       "      <td>0.067646</td>\n",
       "      <td>...</td>\n",
       "      <td>19.487815</td>\n",
       "      <td>29.943834</td>\n",
       "      <td>129.606852</td>\n",
       "      <td>1252.988390</td>\n",
       "      <td>0.147642</td>\n",
       "      <td>0.366100</td>\n",
       "      <td>0.427361</td>\n",
       "      <td>0.160034</td>\n",
       "      <td>0.335305</td>\n",
       "      <td>0.096758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>30.031063</td>\n",
       "      <td>38.469816</td>\n",
       "      <td>202.348085</td>\n",
       "      <td>2172.685795</td>\n",
       "      <td>0.151025</td>\n",
       "      <td>0.318316</td>\n",
       "      <td>0.427291</td>\n",
       "      <td>0.216790</td>\n",
       "      <td>0.302049</td>\n",
       "      <td>0.095889</td>\n",
       "      <td>...</td>\n",
       "      <td>37.090030</td>\n",
       "      <td>52.019299</td>\n",
       "      <td>258.506553</td>\n",
       "      <td>3393.509676</td>\n",
       "      <td>0.226161</td>\n",
       "      <td>0.946440</td>\n",
       "      <td>1.318122</td>\n",
       "      <td>0.406715</td>\n",
       "      <td>0.560010</td>\n",
       "      <td>0.164923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0              1              2              3   \\\n",
       "count  100000.000000  100000.000000  100000.000000  100000.000000   \n",
       "mean       14.098702      19.295169      91.756108     651.800128   \n",
       "std         3.519180       4.446081      24.249636     347.062905   \n",
       "min        -0.281599      -0.140407      -8.731018    -741.775730   \n",
       "25%        11.716777      16.307522      75.354290     417.743091   \n",
       "50%        14.096291      19.296790      91.731903     650.839715   \n",
       "75%        16.470124      22.299332     108.119079     886.710120   \n",
       "max        30.031063      38.469816     202.348085    2172.685795   \n",
       "\n",
       "                  4              5              6              7   \\\n",
       "count  100000.000000  100000.000000  100000.000000  100000.000000   \n",
       "mean        0.096034       0.103642       0.089314       0.048422   \n",
       "std         0.013356       0.052704       0.081072       0.038583   \n",
       "min         0.034892      -0.123739      -0.252489      -0.116072   \n",
       "25%         0.087065       0.068066       0.034279       0.022478   \n",
       "50%         0.096036       0.103706       0.089293       0.048362   \n",
       "75%         0.105055       0.139306       0.144352       0.074431   \n",
       "max         0.151025       0.318316       0.427291       0.216790   \n",
       "\n",
       "                  8              9       ...                   20  \\\n",
       "count  100000.000000  100000.000000      ...        100000.000000   \n",
       "mean        0.180263       0.062772      ...            16.226747   \n",
       "std         0.027709       0.007269      ...             4.818615   \n",
       "min         0.063134       0.028762      ...            -4.958019   \n",
       "25%         0.161636       0.057900      ...            12.987974   \n",
       "50%         0.180319       0.062779      ...            16.219209   \n",
       "75%         0.198926       0.067646      ...            19.487815   \n",
       "max         0.302049       0.095889      ...            37.090030   \n",
       "\n",
       "                  21             22             23             24  \\\n",
       "count  100000.000000  100000.000000  100000.000000  100000.000000   \n",
       "mean       25.709159     106.992103     875.027629       0.132329   \n",
       "std         6.306801      33.518099     560.404074       0.022713   \n",
       "min         0.179834     -42.715090   -1632.642562       0.036083   \n",
       "25%        21.466966      84.442552     498.235106       0.117078   \n",
       "50%        25.704349     106.938066     874.847927       0.132365   \n",
       "75%        29.943834     129.606852    1252.988390       0.147642   \n",
       "max        52.019299     258.506553    3393.509676       0.226161   \n",
       "\n",
       "                  25             26             27             28  \\\n",
       "count  100000.000000  100000.000000  100000.000000  100000.000000   \n",
       "mean        0.256093       0.278126       0.114411       0.291184   \n",
       "std         0.162484       0.219551       0.067366       0.065595   \n",
       "min        -0.465006      -0.585651      -0.159343       0.014209   \n",
       "25%         0.146563       0.129664       0.068884       0.246983   \n",
       "50%         0.255991       0.277674       0.114428       0.291551   \n",
       "75%         0.366100       0.427361       0.160034       0.335305   \n",
       "max         0.946440       1.318122       0.406715       0.560010   \n",
       "\n",
       "                  29  \n",
       "count  100000.000000  \n",
       "mean        0.084052  \n",
       "std         0.018830  \n",
       "min        -0.005314  \n",
       "25%         0.071350  \n",
       "50%         0.084057  \n",
       "75%         0.096758  \n",
       "max         0.164923  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_virt= np.random.multivariate_normal(echmean, echcov, 100000, check_valid ='warn')\n",
    "d_virt=pd.DataFrame(X_virt, columns=X_train.columns)\n",
    "d_virt.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Let's compute the prediction given by our black box oracle (GB with default parameters) on those points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_virt=gbr.predict(d_virt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's now fit a single tree on this large number of synthetic points (we can/should add the original training set to this synthetic training set, but as the later is much larger than the former it's unlikely to make any significant difference). Warning : computation may be a bit lengthy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k= 4 average cross-validation score: 0.983\n",
      "k= 5 average cross-validation score: 0.987\n",
      "k= 6 average cross-validation score: 0.990\n",
      "k= 7 average cross-validation score: 0.992\n",
      "k= 8 average cross-validation score: 0.991\n",
      "k= 9 average cross-validation score: 0.986\n"
     ]
    }
   ],
   "source": [
    " from sklearn.model_selection import cross_val_score\n",
    "for i in range (4,10):\n",
    "    tree = DecisionTreeClassifier(max_depth=i,random_state=42)\n",
    "    score=cross_val_score(tree,d_virt,y_virt,cv=5,scoring= 'roc_auc').mean() \n",
    "    print(\"k=\",i,\"average cross-validation score: {:.3f}\".format(score))    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our trees, (especially with the optimal depth of 7) fit well the virtual training set. But do they fit the real data ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for depth 7\n",
      "accuracy on training set is 0.986\n",
      "accuracy on test set is 0.958\n",
      "roc_auc_score on test set is 0.951\n"
     ]
    }
   ],
   "source": [
    "k=7\n",
    "tree = DecisionTreeClassifier(max_depth=k)\n",
    "tree.fit(d_virt,y_virt)\n",
    "Acc_appr=tree.score(X_train,y_train)\n",
    "Acc_test=tree.score(X_test,y_test)\n",
    "y_pred=tree.predict(X_test)\n",
    "roc_test=roc_auc_score(y_test, y_pred)\n",
    "print('for depth',k)\n",
    "print(\"accuracy on training set is {:.3f}\".format(Acc_appr))\n",
    "print(\"accuracy on test set is {:.3f}\".format(Acc_test))\n",
    "print(\"roc_auc_score on test set is {:.3f}\".format(roc_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Good ! accuracy and roc_auc_score on test set are significantly above the initial tree scores (albeit at the price of increased complexity/depth). Still they are under the GB scores, which was expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try with Random Forest now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_virt=rfc.predict(d_virt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k= 5 average cross-validation score: 0.996\n",
      "k= 6 average cross-validation score: 0.996\n",
      "k= 7 average cross-validation score: 0.996\n",
      "k= 8 average cross-validation score: 0.993\n",
      "k= 9 average cross-validation score: 0.988\n",
      "k= 10 average cross-validation score: 0.980\n"
     ]
    }
   ],
   "source": [
    "for i in range (5,11):\n",
    "    tree1 = DecisionTreeClassifier(max_depth=i,random_state=42)\n",
    "    score=cross_val_score(tree1,d_virt,z_virt,scoring= 'roc_auc',cv=5).mean() \n",
    "    print(\"k=\",i,\"average cross-validation score: {:.3f}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for depth 5\n",
      "accuracy on training set is 0.986\n",
      "accuracy on test set is 0.944\n",
      "roc_auc_score on test set is 0.944\n"
     ]
    }
   ],
   "source": [
    "# again, let's try this tree on the original set\n",
    "k=5\n",
    "tree1 = DecisionTreeClassifier(max_depth=k)\n",
    "tree1.fit(d_virt,y_virt)\n",
    "Acc_appr=tree1.score(X_train,y_train)\n",
    "Acc_test=tree1.score(X_test,y_test)\n",
    "y_pred=tree1.predict(X_test)\n",
    "roc_test=roc_auc_score(y_test, y_pred)\n",
    "print('for depth',k)\n",
    "print(\"accuracy on training set is {:.3f}\".format(Acc_appr))\n",
    "print(\"accuracy on test set is {:.3f}\".format(Acc_test))\n",
    "print(\"roc_auc_score on test set is {:.3f}\".format(roc_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Again, significant improvement over the initial tree. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the sake of illustration, let's now try a different strategy to generate artificial data. Rather than gaussian random draws, we will use a deterministic procedure : take the middle point between each pair of initial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "long=len(X_train)\n",
    "court=len(X_train.columns)\n",
    "X_virt=np.zeros((long*long,court))\n",
    "X_val=X_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(long):\n",
    "    for j in range(long):\n",
    "        for k in range(court):\n",
    "            X_virt[i+long*j,k]=(X_val[i,k]+X_val[j,k])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>181476.000000</td>\n",
       "      <td>181476.000000</td>\n",
       "      <td>181476.000000</td>\n",
       "      <td>181476.000000</td>\n",
       "      <td>181476.000000</td>\n",
       "      <td>181476.000000</td>\n",
       "      <td>181476.000000</td>\n",
       "      <td>181476.000000</td>\n",
       "      <td>181476.000000</td>\n",
       "      <td>181476.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>181476.000000</td>\n",
       "      <td>181476.000000</td>\n",
       "      <td>181476.000000</td>\n",
       "      <td>181476.000000</td>\n",
       "      <td>181476.000000</td>\n",
       "      <td>181476.000000</td>\n",
       "      <td>181476.000000</td>\n",
       "      <td>181476.000000</td>\n",
       "      <td>181476.000000</td>\n",
       "      <td>181476.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.075202</td>\n",
       "      <td>19.295047</td>\n",
       "      <td>91.592911</td>\n",
       "      <td>649.627230</td>\n",
       "      <td>0.096018</td>\n",
       "      <td>0.103460</td>\n",
       "      <td>0.088931</td>\n",
       "      <td>0.048211</td>\n",
       "      <td>0.180203</td>\n",
       "      <td>0.062779</td>\n",
       "      <td>...</td>\n",
       "      <td>16.202542</td>\n",
       "      <td>25.708263</td>\n",
       "      <td>106.803732</td>\n",
       "      <td>872.524413</td>\n",
       "      <td>0.132365</td>\n",
       "      <td>0.256041</td>\n",
       "      <td>0.277706</td>\n",
       "      <td>0.114156</td>\n",
       "      <td>0.291210</td>\n",
       "      <td>0.084079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.478274</td>\n",
       "      <td>3.141389</td>\n",
       "      <td>17.081338</td>\n",
       "      <td>244.329577</td>\n",
       "      <td>0.009426</td>\n",
       "      <td>0.037197</td>\n",
       "      <td>0.057164</td>\n",
       "      <td>0.027193</td>\n",
       "      <td>0.019525</td>\n",
       "      <td>0.005111</td>\n",
       "      <td>...</td>\n",
       "      <td>3.396074</td>\n",
       "      <td>4.456901</td>\n",
       "      <td>23.624039</td>\n",
       "      <td>394.905197</td>\n",
       "      <td>0.015997</td>\n",
       "      <td>0.114667</td>\n",
       "      <td>0.154931</td>\n",
       "      <td>0.047498</td>\n",
       "      <td>0.046171</td>\n",
       "      <td>0.013242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.062510</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.049960</td>\n",
       "      <td>...</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12.255000</td>\n",
       "      <td>17.075000</td>\n",
       "      <td>78.935000</td>\n",
       "      <td>468.187500</td>\n",
       "      <td>0.089445</td>\n",
       "      <td>0.075935</td>\n",
       "      <td>0.043310</td>\n",
       "      <td>0.025865</td>\n",
       "      <td>0.166850</td>\n",
       "      <td>0.059140</td>\n",
       "      <td>...</td>\n",
       "      <td>13.635000</td>\n",
       "      <td>22.535000</td>\n",
       "      <td>88.855000</td>\n",
       "      <td>577.000000</td>\n",
       "      <td>0.121400</td>\n",
       "      <td>0.172050</td>\n",
       "      <td>0.161449</td>\n",
       "      <td>0.077410</td>\n",
       "      <td>0.260650</td>\n",
       "      <td>0.074765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.705000</td>\n",
       "      <td>19.020000</td>\n",
       "      <td>88.955000</td>\n",
       "      <td>590.725000</td>\n",
       "      <td>0.095680</td>\n",
       "      <td>0.098025</td>\n",
       "      <td>0.078720</td>\n",
       "      <td>0.044595</td>\n",
       "      <td>0.178600</td>\n",
       "      <td>0.062025</td>\n",
       "      <td>...</td>\n",
       "      <td>15.565000</td>\n",
       "      <td>25.435000</td>\n",
       "      <td>102.650000</td>\n",
       "      <td>761.850000</td>\n",
       "      <td>0.131908</td>\n",
       "      <td>0.236850</td>\n",
       "      <td>0.255250</td>\n",
       "      <td>0.111263</td>\n",
       "      <td>0.285025</td>\n",
       "      <td>0.081785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.680000</td>\n",
       "      <td>21.230000</td>\n",
       "      <td>102.560000</td>\n",
       "      <td>796.400000</td>\n",
       "      <td>0.102185</td>\n",
       "      <td>0.124925</td>\n",
       "      <td>0.122825</td>\n",
       "      <td>0.064300</td>\n",
       "      <td>0.191650</td>\n",
       "      <td>0.065595</td>\n",
       "      <td>...</td>\n",
       "      <td>18.350000</td>\n",
       "      <td>28.545000</td>\n",
       "      <td>121.450000</td>\n",
       "      <td>1087.300000</td>\n",
       "      <td>0.142700</td>\n",
       "      <td>0.316500</td>\n",
       "      <td>0.371146</td>\n",
       "      <td>0.145890</td>\n",
       "      <td>0.313800</td>\n",
       "      <td>0.090865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2499.000000</td>\n",
       "      <td>0.142500</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426400</td>\n",
       "      <td>0.191300</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.097440</td>\n",
       "      <td>...</td>\n",
       "      <td>33.130000</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>229.300000</td>\n",
       "      <td>3432.000000</td>\n",
       "      <td>0.218400</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0              1              2              3   \\\n",
       "count  181476.000000  181476.000000  181476.000000  181476.000000   \n",
       "mean       14.075202      19.295047      91.592911     649.627230   \n",
       "std         2.478274       3.141389      17.081338     244.329577   \n",
       "min         6.981000       9.710000      43.790000     143.500000   \n",
       "25%        12.255000      17.075000      78.935000     468.187500   \n",
       "50%        13.705000      19.020000      88.955000     590.725000   \n",
       "75%        15.680000      21.230000     102.560000     796.400000   \n",
       "max        28.110000      39.280000     188.500000    2499.000000   \n",
       "\n",
       "                  4              5              6              7   \\\n",
       "count  181476.000000  181476.000000  181476.000000  181476.000000   \n",
       "mean        0.096018       0.103460       0.088931       0.048211   \n",
       "std         0.009426       0.037197       0.057164       0.027193   \n",
       "min         0.062510       0.019380       0.000000       0.000000   \n",
       "25%         0.089445       0.075935       0.043310       0.025865   \n",
       "50%         0.095680       0.098025       0.078720       0.044595   \n",
       "75%         0.102185       0.124925       0.122825       0.064300   \n",
       "max         0.142500       0.345400       0.426400       0.191300   \n",
       "\n",
       "                  8              9       ...                   20  \\\n",
       "count  181476.000000  181476.000000      ...        181476.000000   \n",
       "mean        0.180203       0.062779      ...            16.202542   \n",
       "std         0.019525       0.005111      ...             3.396074   \n",
       "min         0.106000       0.049960      ...             7.930000   \n",
       "25%         0.166850       0.059140      ...            13.635000   \n",
       "50%         0.178600       0.062025      ...            15.565000   \n",
       "75%         0.191650       0.065595      ...            18.350000   \n",
       "max         0.304000       0.097440      ...            33.130000   \n",
       "\n",
       "                  21             22             23             24  \\\n",
       "count  181476.000000  181476.000000  181476.000000  181476.000000   \n",
       "mean       25.708263     106.803732     872.524413       0.132365   \n",
       "std         4.456901      23.624039     394.905197       0.015997   \n",
       "min        12.020000      50.410000     185.200000       0.071170   \n",
       "25%        22.535000      88.855000     577.000000       0.121400   \n",
       "50%        25.435000     102.650000     761.850000       0.131908   \n",
       "75%        28.545000     121.450000    1087.300000       0.142700   \n",
       "max        49.540000     229.300000    3432.000000       0.218400   \n",
       "\n",
       "                  25             26             27             28  \\\n",
       "count  181476.000000  181476.000000  181476.000000  181476.000000   \n",
       "mean        0.256041       0.277706       0.114156       0.291210   \n",
       "std         0.114667       0.154931       0.047498       0.046171   \n",
       "min         0.027290       0.000000       0.000000       0.156500   \n",
       "25%         0.172050       0.161449       0.077410       0.260650   \n",
       "50%         0.236850       0.255250       0.111263       0.285025   \n",
       "75%         0.316500       0.371146       0.145890       0.313800   \n",
       "max         1.058000       1.252000       0.291000       0.663800   \n",
       "\n",
       "                  29  \n",
       "count  181476.000000  \n",
       "mean        0.084079  \n",
       "std         0.013242  \n",
       "min         0.055040  \n",
       "25%         0.074765  \n",
       "50%         0.081785  \n",
       "75%         0.090865  \n",
       "max         0.207500  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_virt=pd.DataFrame(X_virt, columns=X_train.columns)\n",
    "d_virt.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's label those points with the black box prediction\n",
    "y_virt=gbr.predict(d_virt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k= 4 average cross-validation score: 0.992\n",
      "k= 5 average cross-validation score: 0.994\n",
      "k= 6 average cross-validation score: 0.996\n",
      "k= 7 average cross-validation score: 0.997\n",
      "k= 8 average cross-validation score: 0.998\n",
      "k= 9 average cross-validation score: 0.997\n"
     ]
    }
   ],
   "source": [
    "#as above, let(s fit a tree on those data\n",
    "for i in range (4,10):\n",
    "    tree = DecisionTreeClassifier(max_depth=i,random_state=42)\n",
    "    score=cross_val_score(tree,d_virt,y_virt,cv=5,scoring= 'roc_auc').mean() \n",
    "    print(\"k=\",i,\"average cross-validation score: {:.3f}\".format(score))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for depth 8\n",
      "accuracy on training set is 0.991\n",
      "accuracy on test set is 0.951\n",
      "roc_auc_score on test set is 0.949\n"
     ]
    }
   ],
   "source": [
    "#hour of truth : let's look at the predicting ability of this new tree : \n",
    "k=8\n",
    "tree = DecisionTreeClassifier(max_depth=k)\n",
    "tree.fit(d_virt,y_virt)\n",
    "Acc_appr=tree.score(X_train,y_train)\n",
    "Acc_test=tree.score(X_test,y_test)\n",
    "y_pred=tree.predict(X_test)\n",
    "roc_test=roc_auc_score(y_test, y_pred)\n",
    "print('for depth',k)\n",
    "print(\"accuracy on training set is {:.3f}\".format(Acc_appr))\n",
    "print(\"accuracy on test set is {:.3f}\".format(Acc_test))\n",
    "print(\"roc_auc_score on test set is {:.3f}\".format(roc_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quite good ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
